{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем данные с соревнования Dialog Evaluation 2015 по исправлению опечаток. Данные представляют собой набор предложений (правильное - ошибочное). Задача найти слова с ошибками и заменить их на правильный вариант.\n",
    "\n",
    "Недостатком тут является то, что не всегда можно правильно сопоставить слова правильного предложения и ошибочного (из-за слов с пропущенным или добавленным пробелом). Из статьи авторов корпуса не очень понятно, как они решали эту проблему, поэтому я просто удалил все такие предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('../data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('../data/correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пояним эту мысль.\n",
      "Поясним эту мысль\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на пары предложений\n",
    "print(bad[2])\n",
    "print(true[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
    "# разобьем предложение по пробелам и удалим пунктуация на границах слов\n",
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
    "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('апофеозом', 'опофеозом'),\n",
      " ('дня', 'дня'),\n",
      " ('для', 'для'),\n",
      " ('меня', 'меня'),\n",
      " ('сегодня', 'сегодня'),\n",
      " ('стала', 'стала'),\n",
      " ('фраза', 'фраза'),\n",
      " ('услышанная', 'услышанная'),\n",
      " ('в', 'в'),\n",
      " ('новостях', 'новостях')]\n"
     ]
    }
   ],
   "source": [
    "pprint(align_words(true[1], bad[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вытащим только неправильные варианты и заодно посчитаем процент ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = []\n",
    "total = 0\n",
    "\n",
    "for i in range(len(true)):\n",
    "    \n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    \n",
    "    for pair in word_pairs:\n",
    "        if pair[0] != pair[1]:\n",
    "            mistakes.append(pair)\n",
    "        \n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля ошибок -  0.13034358769476628\n"
     ]
    }
   ],
   "source": [
    "print('Доля ошибок - ', len(mistakes)/total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('симпатичнейшее', 'симпатичнейшое'),\n",
       " ('апофеозом', 'опофеозом'),\n",
       " ('поясним', 'пояним'),\n",
       " ('получатся', 'полчатся'),\n",
       " ('очень', 'оччччень')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернем в Counter, чтобы сразу увидеть частотные ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('сегодня', 'седня'), 24),\n",
       " (('вообще', 'вобще'), 18),\n",
       " (('естественно', 'естесственно'), 17),\n",
       " (('вообще', 'ваще'), 17),\n",
       " (('хочется', 'хочеться'), 16),\n",
       " (('кстати', 'кстате'), 16),\n",
       " (('очень', 'ооочень'), 14),\n",
       " (('как-то', 'както'), 9),\n",
       " (('очень', 'оооочень'), 9),\n",
       " (('это', 'ето'), 9)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mistakes).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за того, что процент ошибок довольно низкий, не очень выгодно будет находить исправление для каждого слова. Нужен какой-то более простой классификатор, который выделит ошибочные слова, чтобы потом только их и редактировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ это сделать - составить словарь правильных слов и потом сравнивать с ним. Чтобы не делать этого вручную, можно взять какой-нибудь корпус текстов, прошедщих редактуру. Новостные тексты для этого хорошо подходят."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я заранее собрал небольшой корпус новостных текстов и немного почистил его удалив отдельную пунктуацию и пунктуацию на границах слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('corpus_ng.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['судя', 'по', 'всему', 'русская', 'православная', 'церковь', 'нашла', 'долгожданную', 'национальную', 'идею']\n"
     ]
    }
   ],
   "source": [
    "# нормализация нам тут не нужна так как нужно находить слова в разных формах\n",
    "print(corpus[1].split()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Напишите функцию, которая будет предсказывать ошибочные слова на основе корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создайте множество, чтобы проверять вхождения\n",
    "vocab = set([i for j in corpus for i in j.split()])\n",
    "\n",
    "## ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137738"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mistaken(word, vocab):\n",
    "    '''\n",
    "    ::input: word, vocabulary\n",
    "    ::output: 1 or 0\n",
    "    \n",
    "    '''\n",
    "    if word in vocab:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    ## ваш код здесь\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_mistaken('опофеоз', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для оценки создайте два списка y_true и y_pred\n",
    "# пройдитесь по предложениям\n",
    "# сопоставите слова с помощью функции align_words\n",
    "# пройдитесь по парам слов и\n",
    "# если слова одинаковые добавьте в y_true 0 \n",
    "# если слова разные добавьте в y_true 1\n",
    "# предскажите ошибочность слова из bad списка \n",
    "# добавьте предсказание в список y_pred\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for sent1, sent2 in zip(true, bad):\n",
    "    pairs += align_words(sent1, sent2)\n",
    "\n",
    "## ваш код здесь\n",
    "for right, wrong in pairs:\n",
    "    if right == wrong:\n",
    "        y_true.append(0)\n",
    "    else:\n",
    "        y_true.append(1)\n",
    "    y_pred.append(predict_mistaken(wrong, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('симпатичнейшее', 'симпатичнейшое'),\n",
       " ('шпионское', 'шпионское'),\n",
       " ('устройство', 'устройство'),\n",
       " ('такой', 'такой'),\n",
       " ('себе', 'себе'),\n",
       " ('гламурный', 'гламурный'),\n",
       " ('фотоаппарат', 'фотоаппарат'),\n",
       " ('девушки', 'девушки'),\n",
       " ('бонда', 'бонда'),\n",
       " ('миниатюрная', 'миниатюрная')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.89      0.93      8707\n",
      "          1       0.55      0.88      0.68      1305\n",
      "\n",
      "avg / total       0.92      0.89      0.90     10012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# оцените качество с помощью classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация исправлений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно думать о том, как исправить неправильные слова. Посмотрим как это можно делать на примере известной реализации Питера Норвига."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея - сделать словарь правильных слов (у нас уже есть), расчитать вероятность каждого слова в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in open('../data/corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 67679),\n",
       " ('и', 55933),\n",
       " ('на', 27860),\n",
       " ('не', 21627),\n",
       " ('что', 18299),\n",
       " ('с', 18224),\n",
       " ('по', 13117),\n",
       " ('а', 9696),\n",
       " ('как', 8958),\n",
       " ('к', 8907)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фунцкия расчета вероятности слова\n",
    "N = sum(WORDS.values())\n",
    "def P(word, N=N): \n",
    "    \"Вычисляем вероятность слова\"\n",
    "    return WORDS[word] / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8025455548325345e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('апофеоз')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы найти исправления нужно сгенерировать возможные исправления и выбрать те, которые есть в словаре. Если есть несколько вариантов, то выбрать тот, у котогоро наибольшая вероятность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Находим наиболее вероятное похожее слово\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Генерируем кандидатов на исправление\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"Выбираем слова, которые есть в корпусе\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"Создаем кандидатов, которые отличаются на одну букву\"\n",
    "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"Создаем кандидатов, которые отличаются на две буквы\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 279 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'апофеоз'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('опефеоз')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте поподробнее разберем, что происходит в функции edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'опефеоз'\n",
    "splits = [(word[:i], word[i:])    for i in range(len(word) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'опефеоз'),\n",
       " ('о', 'пефеоз'),\n",
       " ('оп', 'ефеоз'),\n",
       " ('опе', 'феоз'),\n",
       " ('опеф', 'еоз'),\n",
       " ('опефе', 'оз'),\n",
       " ('опефео', 'з'),\n",
       " ('опефеоз', '')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletes = [L + R[1:] for L, R in splits if R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пефеоз', 'оефеоз', 'опфеоз', 'опееоз', 'опефоз', 'опефез', 'опефео']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deletes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['поефеоз', 'оепфеоз', 'опфееоз', 'опеефоз', 'опефоез', 'опефезо']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "replaces = [L + c + R[1:] for L, R in splits if R for c in letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inserts = [L + c + R for L, R in splits for c in letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['йопефеоз',\n",
       " 'цопефеоз',\n",
       " 'уопефеоз',\n",
       " 'копефеоз',\n",
       " 'еопефеоз',\n",
       " 'нопефеоз',\n",
       " 'гопефеоз',\n",
       " 'шопефеоз',\n",
       " 'щопефеоз',\n",
       " 'зопефеоз']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inserts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки используем просто долю правильных исправлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.7333333333333333\n",
      "10\n",
      "0.8384615384615385\n",
      "20\n",
      "0.8441558441558441\n",
      "30\n",
      "0.8434343434343434\n",
      "40\n",
      "0.847953216374269\n",
      "50\n",
      "0.8518518518518519\n",
      "60\n",
      "0.8444444444444444\n",
      "70\n",
      "0.849009900990099\n",
      "80\n",
      "0.8490967056323061\n",
      "90\n",
      "0.8516699410609038\n",
      "100\n",
      "0.850358422939068\n",
      "110\n",
      "0.853904282115869\n",
      "120\n",
      "0.8538283062645011\n",
      "130\n",
      "0.8527472527472527\n",
      "140\n",
      "0.8516746411483254\n",
      "150\n",
      "0.8574144486692015\n",
      "160\n",
      "0.8567216981132075\n",
      "170\n",
      "0.8562605277933745\n",
      "180\n",
      "0.8536324786324786\n",
      "190\n",
      "0.8547094188376754\n",
      "200\n",
      "0.8576238576238576\n",
      "210\n",
      "0.8588929219600726\n",
      "220\n",
      "0.8594687232219366\n",
      "230\n",
      "0.8595482546201232\n",
      "240\n",
      "0.8635485117897178\n",
      "250\n",
      "0.8615497612926919\n",
      "260\n",
      "0.862469222652128\n",
      "270\n",
      "0.8600405679513184\n",
      "280\n",
      "0.8602775088738303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-26dc9df33963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_pairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a7beb491c706>\u001b[0m in \u001b[0;36mcorrection\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"Находим наиболее вероятное похожее слово\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a7beb491c706>\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m\"Генерируем кандидатов на исправление\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medits1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medits2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a7beb491c706>\u001b[0m in \u001b[0;36mknown\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;34m\"Выбираем слова, которые есть в корпусе\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0medits1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a7beb491c706>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;34m\"Выбираем слова, которые есть в корпусе\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0medits1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a7beb491c706>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0medits2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;34m\"Создаем кандидатов, которые отличаются на две буквы\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0medits1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0medits1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# До этого мы уже считали долю ошибок во всех предложениях.\n",
    "# Поэтому если ничего не менять то доля правильных исправлений уже будет 100 - 13 = 87 %.\n",
    "# Наш подход соответственно должен показывать лучший результат \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    \n",
    "    for pair in word_pairs:\n",
    "        \n",
    "        predicted = correction(pair[1])\n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    if not i % 10:\n",
    "        print(i)\n",
    "        print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860593220338983\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 202 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'на'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('нав')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 28 ms, total: 2.08 s\n",
      "Wall time: 2.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'насмехатьсяаававттававаываываы'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('насмехатьсяаававттававаываываы')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим какие исправления выбираются для самых частотных опечаток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сегодня', 'седня', 'сеня'),\n",
       " ('вообще', 'вобще', 'вообще'),\n",
       " ('вообще', 'ваще', 'ваще'),\n",
       " ('естественно', 'естесственно', 'естественно'),\n",
       " ('хочется', 'хочеться', 'хочется'),\n",
       " ('кстати', 'кстате', 'кстати'),\n",
       " ('очень', 'ооочень', 'очень'),\n",
       " ('как-то', 'както', 'какао'),\n",
       " ('очень', 'оооочень', 'оооочень'),\n",
       " ('это', 'ето', 'ето')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wt[0], wt[1], correction(wt[1])) for wt, _ in Counter(mistakes).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики близости слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо того, чтобы генерировать все варианты, можно искать похожие слова в словаре. Для этого нужно задать метрику похожести. Для исправления опечаток часто используются расстояния редактирования (количество редактирований, которые нужно сделать в строке a, чтобы прийти к b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в питоне есть библиотеке для нахождения близких строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 962 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['апофеоз']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_close_matches('опофеоз', WORDS.keys(), n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает тоже не очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недавно вышла библиотека, в которой реализованы многие методы нахождения расстояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.7142857142857143)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('опофиоз', WORDS, textdistance.hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.8571428571428572)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('апофиоз', WORDS, textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ждать так долго мы не можем, поэтому попробуем что-то побыстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие вещи, которые медленно решаются в питоне, можно оптимизировать с помощью матричных и векторных операций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем поиск похожих по векторам символов, из которых состоит слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in open('../data/corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, TOPN=3):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)\n",
    "    topn = similarities.argsort()[0][:TOPN]\n",
    "    \n",
    "    return [id2word[top] for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 111 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['апофеоз', 'апофеозом', 'апофеоза']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_vec('опофеоз', X, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию, которая принимает слово и находит ближайшее к нему в словаре (сгенерируйте несколько кандидатов с помощью get_closest_match_vec, а затем посчитайте метрики близости до кадого слова и выведете самое близкое). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, metric=textdistance.levenshtein):\n",
    "    # ваш код здесь\n",
    "    closest_matches = get_closest_match_vec(text, X, vec, TOPN=10)\n",
    "    closest = get_closest_match_with_metric(text, closest_matches)[0]\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'алкоголь'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('алкогнль', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оцените качество также как и раньше (если будет долго работать возьмите кусок данных)\n",
    "# посмотрите на ошибки\n",
    "def test_checker(checker, corpus_limit=None):\n",
    "    #print('\\t'.join(['mistake','predicted','true']))\n",
    "    impropers = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if not corpus_limit:\n",
    "        corpus_limit = len(true)\n",
    "\n",
    "    for i in range(corpus_limit):\n",
    "        word_pairs = align_words(true[i], bad[i])\n",
    "\n",
    "        for pair in word_pairs:\n",
    "\n",
    "            predicted = checker(pair[1], X, vec)\n",
    "            if predicted == pair[0]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                impropers.append((pair[1], predicted, pair[0]))\n",
    "            total += 1\n",
    "    \n",
    "    return correct/total, impropers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как функция долго работает, возьмём первую сотню текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score, improperly_corrected = test_checker(get_closest_hybrid_match, corpus_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172817281728173"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(improperly_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рассмотренных методах при выборе исправления никак не использовался контекст. Про то как это можно сделать, можно почитать вот тут - https://habr.com/ru/post/346618/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать pymorphy2, чтобы улучшить качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_tag(taglist, tags):\n",
    "    for tag in taglist:\n",
    "        if tag.POS in tags:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_closest_hybrid_match_with_morpho(text, X, vec, metric=textdistance.levenshtein):\n",
    "    # ваш код здесь\n",
    "    analyzer = pymorphy2.analyzer.MorphAnalyzer()\n",
    "    ##\n",
    "    pos_tags = [i.POS for i in analyzer.tag(text)]\n",
    "    ## оставляем только те слова, которые тэггятся теми же тегами\n",
    "    closest_matches = [i for i in get_closest_match_vec(text, X, vec, TOPN=10) if same_tag(analyzer.tag(i), pos_tags)]\n",
    "    if closest_matches:\n",
    "        closest = get_closest_match_with_metric(text, closest_matches)[0]\n",
    "    else:\n",
    "        closest = text\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score, improperly_corrected = test_checker(get_closest_hybrid_match_with_morpho, corpus_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8145814581458146"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('симпатичнейшое', 'пластичнейшими', 'симпатичнейшее'),\n",
       " ('шпионское', 'шпионские', 'шпионское'),\n",
       " ('гламурный', 'лагерный', 'гламурный'),\n",
       " ('бонда', 'банда', 'бонда'),\n",
       " ('superheadz', 'super', 'superheadz'),\n",
       " ('clap', 'place', 'clap'),\n",
       " ('camera', 'caterham', 'camera'),\n",
       " ('полчатся', 'ополчатся', 'получатся'),\n",
       " ('язычки', 'язычка', 'язычки'),\n",
       " ('оччччень', 'чечни', 'очень'),\n",
       " ('милые', 'милым', 'милые'),\n",
       " ('нащщот', 'защищено', 'насчет'),\n",
       " ('чавеса', 'чавес', 'чавеса'),\n",
       " ('попавшим', 'пропавшим', 'попавшим'),\n",
       " ('аварийно-спасательных',\n",
       "  'аварийно-восстановительных',\n",
       "  'аварийно-спасательных'),\n",
       " ('вобщем', 'общем', 'в'),\n",
       " ('как', 'как', 'общем'),\n",
       " ('вы', 'вы', 'как'),\n",
       " ('знаете', 'знаете', 'вы'),\n",
       " ('из', 'из', 'знаете'),\n",
       " ('моего', 'моего', 'из'),\n",
       " ('не', 'не', 'моего'),\n",
       " ('давнего', 'давнего', 'недавнего'),\n",
       " ('пропажу', 'продажу', 'пропажу'),\n",
       " ('почте.ру', 'лента.ру', 'почте.ру'),\n",
       " ('хороше', 'шорох', 'хорошо'),\n",
       " ('рите', 'триесте', 'рите'),\n",
       " ('патаму', 'аппарату', 'потому'),\n",
       " ('шта', 'шт', 'что'),\n",
       " ('лчше', 'чаше', 'лучше'),\n",
       " ('переждать', 'опережать', 'переждать'),\n",
       " ('дубраве', 'дубрава', 'дубраве'),\n",
       " ('люминала', 'людмила', 'люминала'),\n",
       " ('поффтыкав', 'поффтыкав', 'повтыкав'),\n",
       " ('билетным', 'блатным', 'билетным'),\n",
       " ('кассам', 'классам', 'кассам'),\n",
       " ('чтото', 'отчетов', 'что-то'),\n",
       " ('мошный', 'машинный', 'мощный'),\n",
       " ('нерабочем', 'рабочем', 'нерабочем'),\n",
       " ('кредиток', 'кредит', 'кредиток'),\n",
       " ('хороше', 'шорох', 'хорошо'),\n",
       " ('капулетти', 'капулети', 'капулетти'),\n",
       " ('прислужницу', 'пружину', 'прислужницу'),\n",
       " ('кормилицу', 'кормилица', 'кормилицу'),\n",
       " ('молодеж', 'молодежи', 'молодежь'),\n",
       " ('седня', 'сиднея', 'сегодня'),\n",
       " ('притащиться', 'приобщиться', 'притащиться'),\n",
       " ('программист', 'программисты', 'программист'),\n",
       " ('вешать', 'вешать', 'навешать'),\n",
       " ('оплеух', 'оплеуху', 'оплеух'),\n",
       " ('пивоварах', 'провалах', 'пивоварах'),\n",
       " ('эт', 'эт', 'это'),\n",
       " ('канешна', 'канешна', 'конечно'),\n",
       " ('4:0', '1:0', '4:0'),\n",
       " ('начальнег', 'градоначальник', 'начальник'),\n",
       " ('зажог', 'зажог', 'зажег'),\n",
       " ('павзрослому', 'взрослому', 'по-взрослому'),\n",
       " ('покрытый', 'покрытые', 'покрытый'),\n",
       " ('слег', 'лег', 'слег'),\n",
       " ('ветрянка', 'ветряке', 'ветрянка'),\n",
       " ('подсаживаеться', 'подсаживался', 'подсаживается'),\n",
       " ('женшина', 'жанне', 'женщина'),\n",
       " ('загруживаюсь', 'погружаюсь', 'загруживаюсь'),\n",
       " ('какието', 'катки', 'какие-то'),\n",
       " ('малолетнии', 'миллиона', 'малолетние'),\n",
       " ('трагичность', 'трагичности', 'трагичность'),\n",
       " ('потерянная', 'потрясенная', 'потерянная'),\n",
       " ('молодеж', 'молодежи', 'молодежь'),\n",
       " ('ощушаю', 'ощушаю', 'ощущаю'),\n",
       " ('монголойдом', 'монологом', 'монголоидом'),\n",
       " ('молчала', 'молчал', 'молчала'),\n",
       " ('молчю', 'молчанию', 'молчу'),\n",
       " ('языковый', 'языковой', 'языковый'),\n",
       " ('баръер', 'турбъерн', 'барьер'),\n",
       " ('сашкой', 'сошкой', 'сашкой'),\n",
       " ('неудобны', 'неудобно', 'неудобны'),\n",
       " ('плоскостопых', 'плоскостях', 'плоскостопых'),\n",
       " ('обълись', 'объединились', 'объелись'),\n",
       " ('пиццы', 'пицца', 'пиццы'),\n",
       " ('распрашивая', 'спрашивая', 'расспрашивая'),\n",
       " ('иностранцев-гостей', 'интернет-сайтов', 'иностранцев-гостей'),\n",
       " ('впечатлении', 'впечатление', 'впечатлении'),\n",
       " ('зубодробительня', 'возбудитель', 'зубодробительная'),\n",
       " ('гребенка', 'ребенка', 'гребенка'),\n",
       " ('ненавистный', 'ненавистной', 'ненавистный'),\n",
       " ('каааак', 'карамалак', 'как'),\n",
       " ('изводить', 'возводить', 'изводить'),\n",
       " ('пергамент', 'регламент', 'пергамент'),\n",
       " ('писмена', 'писанием', 'письмена'),\n",
       " ('штучка', 'штука', 'штучка'),\n",
       " ('расщифровать', 'расформировать', 'расшифровать'),\n",
       " ('самойто', 'самойто', 'самой-то'),\n",
       " ('тул', 'ул', 'тут'),\n",
       " ('ваще', 'ваще', 'вообще'),\n",
       " ('тока', 'тока', 'только'),\n",
       " ('навернео', 'верона', 'наверное'),\n",
       " ('сынишке', 'солнышке', 'сынишке'),\n",
       " ('покорми', 'покормил', 'покорми'),\n",
       " ('сшить', 'сушить', 'сшить'),\n",
       " ('доделала', 'доделал', 'доделала'),\n",
       " ('както', 'каток', 'как-то'),\n",
       " ('легитимизирует', 'делегитимизирует', 'легитимизирует'),\n",
       " ('мущщину', 'сущим', 'мужчину'),\n",
       " ('озаботил', 'озаботился', 'озаботил'),\n",
       " ('никада', 'канда', 'никогда'),\n",
       " ('отключает', 'отключат', 'отключает'),\n",
       " ('потовые', 'портовые', 'потовые'),\n",
       " ('слюнные', 'юные', 'слюнные'),\n",
       " ('nettrader', 'trade', 'nettrader'),\n",
       " ('варикоза', 'зарисовка', 'варикоза'),\n",
       " ('съездели', 'съездил', 'съездили'),\n",
       " ('купим', 'купи', 'купим'),\n",
       " ('пришлесь', 'пришлись', 'пришлось'),\n",
       " ('бд', 'бед', 'бд'),\n",
       " ('программирования', 'программирование', 'программирования'),\n",
       " ('navision', 'vision', 'navision'),\n",
       " ('axapta', 'caasta', 'axapta'),\n",
       " ('опаслася', 'спасая', 'опасался'),\n",
       " ('экземпляром', 'экземпляров', 'экземпляром'),\n",
       " ('сабжа', 'саботажа', 'сабжа'),\n",
       " ('однажэды', 'надежды', 'однажды'),\n",
       " ('обезумевшая', 'обезумевший', 'обезумевшая'),\n",
       " ('раскидала', 'раскидал', 'раскидала'),\n",
       " ('зуные', 'разумные', 'зубные'),\n",
       " ('щетки', 'щеки', 'щетки'),\n",
       " ('пользоваццо', 'пловца', 'пользоваться'),\n",
       " ('бредовую', 'боевую', 'бредовую'),\n",
       " ('грибной', 'гибкой', 'грибной'),\n",
       " ('покатавшись', 'покопавшись', 'покатавшись'),\n",
       " ('радуге', 'радуги', 'радуге'),\n",
       " ('креатифф', 'трафике', 'креатив'),\n",
       " ('нсли', 'несли', 'если'),\n",
       " ('экономикса', 'экономика', 'экономикса'),\n",
       " ('челка', 'пчелка', 'челка'),\n",
       " ('отросла', 'строила', 'отросла'),\n",
       " ('стричься', 'отречься', 'стричься'),\n",
       " ('слишклм', 'шкловским', 'слишком'),\n",
       " ('однимает', 'поднимает', 'обнимает'),\n",
       " ('эриды', 'эры', 'эриды'),\n",
       " ('получаеться', 'получаться', 'получается'),\n",
       " ('самооценка', 'оценка', 'самооценка'),\n",
       " ('разрушаеться', 'разрушаться', 'разрушается'),\n",
       " ('спереди', 'посреди', 'спереди'),\n",
       " ('правила', 'правила', 'правило'),\n",
       " ('кстате', 'остатке', 'кстати'),\n",
       " ('бодрый', 'добрый', 'бодрый'),\n",
       " ('православном', 'православному', 'православном'),\n",
       " ('нисхождении', 'нахождении', 'нисхождении'),\n",
       " ('нмного', 'намного', 'немного'),\n",
       " ('тосковать', 'толковать', 'тосковать'),\n",
       " ('однообразия', 'однообразие', 'однообразия'),\n",
       " ('открыывю', 'открытию', 'открываю'),\n",
       " ('написанно', 'пансион', 'написано'),\n",
       " ('высыпвние', 'пивные', 'высыпание'),\n",
       " ('забавен', 'забавно', 'забавен'),\n",
       " ('тряпки', 'тряпка', 'тряпки'),\n",
       " ('полуживой', 'пожилой', 'полуживой'),\n",
       " ('хламину', 'махину', 'хламину'),\n",
       " ('классная', 'классовая', 'классная'),\n",
       " ('кстате', 'остатке', 'кстати'),\n",
       " ('чтото', 'отчетов', 'что-то'),\n",
       " ('философско-антропологической',\n",
       "  'философско-теологический',\n",
       "  'философско-антропологической'),\n",
       " ('валли', 'вали', 'валли'),\n",
       " ('каком-никаком', 'каком-то', 'каком-никаком'),\n",
       " ('напряге', 'напряга', 'напряге'),\n",
       " ('каталась', 'катилась', 'каталась'),\n",
       " ('собстно', 'собстно', 'собственно'),\n",
       " ('огроменных', 'огромных', 'огроменных'),\n",
       " ('крестов', 'тресков', 'крестов'),\n",
       " ('сохраю', 'сохраняю', 'сохраню'),\n",
       " ('сыро', 'сыр', 'сыро'),\n",
       " ('ваще', 'ваще', 'вообще'),\n",
       " ('ат', 'трата', 'ад'),\n",
       " ('делающие', 'делающее', 'делающие'),\n",
       " ('первй', 'впервой', 'первый'),\n",
       " ('никада', 'канда', 'никогда'),\n",
       " ('угадаете', 'угадайте', 'угадаете'),\n",
       " ('кстате', 'остатке', 'кстати'),\n",
       " ('пожже', 'пежо', 'позже'),\n",
       " ('когдато', 'догадок', 'когда-то'),\n",
       " ('прокорм', 'пороком', 'прокорм'),\n",
       " ('ваще', 'ваще', 'вообще'),\n",
       " ('джойстер', 'джойс', 'джойстер'),\n",
       " ('фсе', 'фе', 'все'),\n",
       " ('сань', 'синь', 'сань'),\n",
       " ('похудения', 'похудение', 'похудения'),\n",
       " ('нащет', 'навещает', 'насчет'),\n",
       " ('гуливера', 'гулиева', 'гулливера'),\n",
       " ('самыи', 'саммиты', 'самый'),\n",
       " ('своеи', 'освоении', 'своей'),\n",
       " ('но', 'но', 'на'),\n",
       " ('попятную', 'понятную', 'попятную'),\n",
       " ('не-как', 'кое-как', 'никак'),\n",
       " ('обидели', 'обидел', 'обидели'),\n",
       " ('рекоммендация', 'рекомендация', 'рекомендации'),\n",
       " ('горок', 'горского', 'горок'),\n",
       " ('удалитъ', 'капиталъ', 'удалить'),\n",
       " ('рэмонт', 'ромэн', 'ремонт'),\n",
       " ('жесть', 'тяжесть', 'жесть'),\n",
       " ('руки-ноги', 'руки-то', 'руки-ноги'),\n",
       " ('раскину', 'рискну', 'раскину'),\n",
       " ('растопырить', 'распространить', 'растопырить'),\n",
       " ('ваще', 'ваще', 'вообще'),\n",
       " ('снежинка', 'снежинки', 'снежинка'),\n",
       " ('еше', 'еше', 'еще'),\n",
       " ('расплющиваются', 'вращаются', 'расплющиваются')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improperly_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
